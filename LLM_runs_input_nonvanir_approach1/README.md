# LLM Runs Input Non-Vanir Approach 1

This script processes vulnerability data from a JSON file, applies patches using a Generative AI model (Gemini), and outputs an updated JSON file along with a report.

## Prerequisites

- Python 3.x
- Pip (Python package installer)
- Google API Key with access to Gemini models.

## Setup

1.  **Clone the repository (if you haven't already):**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```

3.  **Install dependencies:**
    The script uses `google-generativeai`, `python-dotenv`, and `logfire`. Ensure these are listed in a `requirements.txt` file or install them manually:
    ```bash
    pip install google-generativeai python-dotenv logfire
    ```
    If a `requirements.txt` file exists in the parent directory or this directory, you can use:
    ```bash
    pip install -r requirements.txt 
    ```
    *(Adjust path to `requirements.txt` if necessary)*

4.  **Set up environment variables:**
    Create a `.env` file in the root directory of this script (or where it's executed from) and add your Google API key:
    ```env
    GOOGLE_API_KEY1="YOUR_GOOGLE_API_KEY"
    ```
    Replace `"YOUR_GOOGLE_API_KEY"` with your actual API key.

## Running the Script

The script `approach1.py` takes two mandatory arguments and one optional argument:

1.  `input_json_file_path`: (Required) Path to the input JSON file containing vulnerability data.
2.  `target_downstream_version`: (Required) The downstream version string to filter by (e.g., "14", "13").
3.  `--output_json_path` or `-o`: (Optional) Path to save the output JSON file. If not provided, it defaults to `outputs/output_android_{version}_{timestamp}.json`.

**Command Syntax:**

```bash
python LLM_runs_input_nonvanir_approach1/approach1.py <input_json_file_path> <target_downstream_version> [-o <output_json_path>]
```

**Examples:**

1.  **Basic execution (output to default location):**
    This command will process `inputs/filtered_failures_android_14_2025_with_context_3_5_10_20.json`, targeting entries with downstream version "14". The output JSON and report will be saved in the `outputs/` and `outputs/report/` directories respectively, with filenames including "14" and the current timestamp.

    ```bash
    python LLM_runs_input_nonvanir_approach1/approach1.py LLM_runs_input_nonvanir_approach1/inputs/filtered_failures_android_14_2025_with_context_3_5_10_20.json "14"
    ```

2.  **Specifying an output file path:**
    This command will process the same input file for version "14" but will save the main output JSON to `LLM_runs_input_nonvanir_approach1/outputs/custom_output.json`. The report will still go to the default `outputs/report/` directory.

    ```bash
    python LLM_runs_input_nonvanir_approach1/approach1.py LLM_runs_input_nonvanir_approach1/inputs/filtered_failures_android_14_2025_with_context_3_5_10_20.json "14" -o LLM_runs_input_nonvanir_approach1/outputs/custom_output.json
    ```

## Input JSON Format

The script expects an input JSON file that is a list of vulnerability objects. Each object should have an `id` and a `failures` list. Each failure object can contain `downstream_version` and `file_conflicts`. Each `file_conflict` object should have `file_name`, `rej_file_content` (the patch/diff), and `downstream_file_content` (the vulnerable code).

Example structure:
```json
[
  {
    "id": "VULN-001",
    "failures": [
      {
        "downstream_version": "14",
        "downstream_patch": "commit_sha_abc123",
        "repo_path": "path/to/repo",
        "file_conflicts": [
          {
            "file_name": "example.c",
            "rej_file_content": "--- a/example.c\n+++ b/example.c\n@@ -1,3 +1,3 @@\n-old line\n+new line\n // rest of diff",
            "downstream_file_content": "old line\n// original content of example.c"
          }
          // ... more file conflicts
        ]
      }
      // ... more failures
    ]
  }
  // ... more vulnerabilities
]
```

## Output

The script generates two main outputs:

1.  **Processed JSON File:**
    -   Located at the path specified by `--output_json_path` or the default path (`outputs/output_android_{version}_{timestamp}.json`).
    -   This file is a copy of the input JSON, with an added `downstream_llm_output` field in the `file_conflict` objects that were successfully processed. This field contains the patched code generated by the LLM.

2.  **Summary Report JSON File:**
    -   Located in the `outputs/report/` directory, with a filename like `{version}_{timestamp}.json`.
    -   This file contains a summary of the run, including:
        -   Timestamp and input parameters.
        -   Counts of total file conflicts, files attempted, successfully processed files, and skipped/errored files.
        -   Logs of successfully processed files and skipped/errored files with reasons.

## Script Logic Overview

1.  **Initialization:**
    -   Loads environment variables (especially `GOOGLE_API_KEY1`).
    -   Configures the Google Generative AI client.
    -   Defines a `GeminiAgent` for interacting with the LLM.
    -   Sets up argument parsing for command-line inputs.

2.  **Data Loading & Preparation:**
    -   Reads the input JSON file.
    -   Creates a deep copy of the input data to store modifications.
    -   Initializes a `report_data` dictionary to collect statistics.

3.  **Processing Vulnerabilities:**
    -   Iterates through each vulnerability item in the (copied) input data.
    -   For each vulnerability, iterates through its `failures`.
    -   Filters failures based on the `target_downstream_version` provided via command line.
    -   For each matching failure, iterates through its `file_conflicts`.

4.  **Processing File Conflicts:**
    -   For each `file_conflict`:
        -   Retrieves `rej_file_content` (patch) and `downstream_file_content` (vulnerable code).
        -   Performs basic validation (e.g., checks for missing content).
        -   If validation passes, it calls `process_single_entry`.
        -   `process_single_entry` constructs a detailed prompt for the `GeminiAgent` including the patch and vulnerable code.
        -   The agent attempts to apply the patch and resolve conflicts.
        -   If successful, the `modified_code` (patched code) is returned.
        -   The `modified_code` is added as `downstream_llm_output` to the `file_conflict` object in the output data.
        -   Updates counters in `report_data` for successful, skipped, or errored processing.

5.  **Output Generation:**
    -   Saves the modified data (with `downstream_llm_output` fields) to the main output JSON file.
    -   Saves the `report_data` dictionary to the summary report JSON file.

The script uses asynchronous operations (`async`/`await`) for potentially long-running LLM calls.



Example command:
```bash
python approach1.py inputs/filtered_failures_android_14_2025_with_context_3_5_10_20.json 14
```