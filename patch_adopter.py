r"""Applies downloaded patches to a target source code directory.

This module is the third and fifth step in the patch management pipeline. It is
responsible for taking a downloaded .diff file and attempting to apply it to a
local source code repository using the GNU `patch` utility.

It is run twice:
1.  `--source Vanir`: To apply the original, unaltered patches that were
    downloaded by the patch fetcher. It generates a report detailing which
    patches succeeded and which failed.
2.  `--source LLM`: To apply the patches that have been corrected by the
    LLM.

The script generates a detailed JSON report of the application results,
including the status for each patch (e.g., applied cleanly, applied with
offsets, or rejected) and captures any `.rej` files for failed hunks.

Usage:
  # To apply original patches from the fetcher
  python patch_adopter.py --source Vanir

  # To apply patches generated by the LLM
  python patch_adopter.py --source LLM
"""

import argparse
import json
import os
import re
import subprocess
import sys
import time
from pathlib import Path
from typing import List, Dict
import logging
import yaml

# Get a logger for this module
logger = logging.getLogger(__name__)


# --- Load Configuration ---
CONFIG_PATH = Path(__file__).resolve().parent / "config.yaml"
if not CONFIG_PATH.exists():
    raise FileNotFoundError(f"Configuration file not found at {CONFIG_PATH}")

with open(CONFIG_PATH, "r") as f:
    config = yaml.safe_load(f)

PATCH_ADOPTER_CONFIG = config.get("patch_adopter", {})
PATHS_CONFIG = config.get("paths", {})
# --- End Load Configuration ---


# --- Argument Parser ---
def parse_args():
    """Parses command-line arguments."""
    parser = argparse.ArgumentParser(
        description="Apply patches to a target source directory."
    )
    parser.add_argument(
        "--source",
        type=str,
        required=True,
        choices=["Vanir", "LLM"],
        help="The source of the patches ('Vanir' or 'LLM')."
    )
    return parser.parse_args()


# --- Constants ---
BASE_DIR = Path(__file__).resolve().parent
REPORTS_DIR = BASE_DIR / "reports"


class PatchAdopter:
    """
    Manages the application of patch files to a source code repository.
    """

    def __init__(self, target_source_path: str, patch_dir: str,
                 report_output_path: str, strip_level: int = 1,
                 patch_command: str = "patch"):
        """Initializes the PatchAdopter.

        Args:
            target_source_path: The path to the root of the source code checkout (e.g., AOSP root).
            patch_dir: The directory containing the .def patch files.
            report_output_path: The path to save the JSON report.
            strip_level: The '-p' level for the patch command.
            patch_command: The patch executable to use.
        """
        if not os.path.isdir(target_source_path):
             logger.error(f"Target source root not found at '{target_source_path}'")
             sys.exit(1)
        self.target_source_path = target_source_path
        self.patch_dir = patch_dir
        self.report_output_path = report_output_path
        self.strip_level = strip_level
        self.patch_command = patch_command
        self.patch_results = {"patches": []}

    def apply_patch(self, patch_info: dict, source: str = "Vanir") -> dict:
        """
        Attempts to apply a single patch file to the target source directory.

        Args:
            patch_info: A dictionary from the parsed report containing patch details.
            source: The source of the patch ('Vanir' or 'LLM').

        Returns:
            A dictionary containing the detailed results of the patch attempt.
        """
        patch_filename = os.path.basename(patch_info.get("output_path") or patch_info.get("patch_file", ""))
        patch_file = os.path.join(self.patch_dir, patch_filename)
        patch_url = patch_info.get("patch_url") or patch_info.get("original_patch_url")
        project_rel_path = patch_info.get("project")

        base_result = {
            "patch_file": patch_filename, "patch_url": patch_url,
            "source": source, "project": project_rel_path
        }
        
        if not project_rel_path:
            return {**base_result, "status": "Rejected",
                    "detailed_status": "Rejected: Missing project path in report",
                    "message_output": "Patch entry in JSON report is missing the 'project' key."}
        
        # Flexibly determine the correct project path. It can be the AOSP root
        # or a specific project directory provided by the user.
        target_source_path = Path(self.target_source_path)
        if str(target_source_path).endswith(project_rel_path):
            project_abs_path = target_source_path
        else:
            project_abs_path = target_source_path / project_rel_path

        if not project_abs_path.is_dir():
            return {**base_result, "status": "Rejected",
                    "detailed_status": f"Rejected: Project directory not found",
                    "message_output": f"Could not find project directory at: {project_abs_path}"}
            
        if not os.path.exists(patch_file):
            return {**base_result, "status": "Rejected",
                    "detailed_status": "Rejected: Missing Patch File",
                    "message_output": f"Patch file not found: {patch_file}"}

        try:
            # Run the patch command from within the specific project's directory.
            # This is the key to fixing the "file not found" errors.
            result = subprocess.run(
                [self.patch_command, "-p", str(self.strip_level), "-i",
                 patch_file, "-f", "--ignore-whitespace"],
                cwd=str(project_abs_path),
                text=True,
                capture_output=True,
                check=False
            )
            console_output = result.stdout + result.stderr
            return_code = result.returncode

            detailed_status = self._determine_detailed_status(console_output, return_code)
            failed_files_from_run = self._extract_failed_files(console_output)
            
            if "FAILED" not in detailed_status:
                logger.info(f"  -> ✅ {detailed_status}")
            else:
                logger.error(f"  -> ❌ {detailed_status} in project '{project_rel_path}'")

            reject_file_paths = self._get_rej_files(project_abs_path)
            formatted_rejected_files = self._map_rejected_files(
                failed_files_from_run, reject_file_paths, project_abs_path)

            if "Rejected" in detailed_status or "Skipped" in detailed_status:
                overall_status = "Rejected"
            else:
                overall_status = "Applied Successfully"

            return {**base_result, "status": overall_status,
                    "detailed_status": detailed_status,
                    "rejected_files": formatted_rejected_files,
                    "message_output": console_output}

        except Exception as e:
            return {**base_result, "status": "Rejected",
                    "detailed_status": "Rejected: Error Running Patch Command",
                    "message_output": str(e)}

    def _determine_detailed_status(self, console_output: str, return_code: int) -> str:
        """
        Analyzes patch command output and exit code to determine a detailed status.
        The exit code is the most reliable indicator.
        - 0: Success
        - 1: Hunks failed
        - 2: Serious error
        """
        # Trust the exit code first.
        if return_code == 0:
            if "offset" in console_output:
                return "Applied Successfully: With Offsets"
            # Handle cases where patch says it's already applied.
            if "Reversed (or previously applied) patch detected" in console_output:
                return "Applied Successfully: Already Applied"
            return "Applied Successfully: Clean"

        if return_code == 1:
            return "Rejected: Failed Hunks"

        if return_code > 1:
            if "can't find file to patch" in console_output:
                return "Skipped: Files Not Found"
            return "Rejected: Error Running Patch Command"

        # Fallback for edge cases where return code might be misleading.
        if "FAILED" in console_output:
            return "Rejected: Failed Hunks"
            
        return "Unknown Status"

    def _extract_failed_files(self, console_output: str) -> list[str]:
        """
        Parses patch command output to find the names of all files that had at
        least one hunk failure.
        """
        failed_files = set()
        current_file = None
        for line in console_output.splitlines():
            # Check for the file being patched
            patching_match = re.match(r"(?:checking|patching) file (.+)", line)
            if patching_match:
                current_file = patching_match.group(1).strip()
            
            # If we see a failure, add the current file to our set
            if "FAILED" in line and "hunk" in line.lower() and current_file:
                failed_files.add(current_file)
        
        return list(failed_files)

    def _get_rej_files(self, search_path: str) -> list[str]:
        """Finds all `.rej` files within the specified search path."""
        time.sleep(0.5)  # Give the filesystem a moment to create .rej files.
        reject_files = []
        for root, _, files in os.walk(search_path):
            for file in files:
                if file.endswith(".rej"):
                    reject_files.append(os.path.join(root, file))
        return reject_files

    def _map_rejected_files(self, failed_files: list[str],
                              reject_files: list[str], project_abs_path: str) -> list[dict]:
        """Maps failed file paths to their corresponding `.rej` file paths."""
        rejected_mappings = []
        # Create a quick lookup for reject files using their relative paths to the project.
        rej_lookup = {os.path.relpath(p, project_abs_path): p for p in reject_files}

        for failed_file_rel_path in failed_files:
            # The .rej file has the same relative path as the failed file.
            expected_rej_rel_path = failed_file_rel_path + ".rej"
            
            # The full path to the source file that failed.
            full_failed_path = os.path.join(project_abs_path, failed_file_rel_path)
            full_rej_path = rej_lookup.get(expected_rej_rel_path)

            if full_rej_path and os.path.exists(full_rej_path):
                try:
                    with open(full_rej_path, 'r', encoding='utf-8', errors='ignore') as f:
                        rej_content = f.read()
                except Exception as e:
                    rej_content = f"Error reading .rej file: {e}"

                rejected_mappings.append({
                    "failed_file": full_failed_path,
                    "reject_file": full_rej_path,
                    "rej_content": rej_content
                })
            else:
                logger.warning(f"A hunk failure was noted for '{failed_file_rel_path}', "
                               "but its corresponding .rej file was not found. It will be skipped.")
        
        return rejected_mappings

    def save_report(self):
        """Saves the cumulative patch results to a JSON file."""
        with open(self.report_output_path, "w", encoding="utf-8") as report:
            json.dump(self.patch_results, report, indent=4)
        logger.info(f"📄 Patch report saved to: {self.report_output_path}")

    def generate_summary(self):
        """Prints a summary of the patch application results to the console."""
        status_counts = {}
        failed_patches_count = 0
        for patch in self.patch_results["patches"]:
            detailed_status = patch.get("detailed_status", "Unknown")
            status_counts[detailed_status] = status_counts.get(
                detailed_status, 0) + 1
            if patch.get("status") == "Rejected":
                failed_patches_count += 1
        
        summary = {
            "total_patches": len(self.patch_results["patches"]),
            "failed_patches": failed_patches_count,
            "status_counts": status_counts
        }

        summary_text = f"\n{'='*40}\n"
        summary_text += "Patch Application Summary\n"
        summary_text += f"{'='*40}\n"
        summary_text += f"Total patches processed: {summary['total_patches']}\n"
        summary_text += "Status breakdown:\n"
        for status, count in status_counts.items():
            summary_text += f"  - {status}: {count}\n"
        summary_text += "="*40
        logger.info(summary_text)
        return summary


def run_adoption_step(source: str, target_source_path: str):
    """
    Runs the appropriate patch adoption step based on the source.

    Args:
        source (str): The patch source ('Vanir' or 'LLM').
        target_source_path (str): Path to the target source code directory.
    """
    start_time = time.time()
    logger.info(f"Running adoption for '{source}' patches...")

    if source == "Vanir":
        input_json = BASE_DIR / PATHS_CONFIG.get("parsed_vanir_report")
        patch_dir = BASE_DIR / PATHS_CONFIG.get("fetched_patches_dir")
        report_output_path = BASE_DIR / PATHS_CONFIG.get("vanir_patch_application_report")
    else:  # LLM
        input_json = BASE_DIR / PATHS_CONFIG.get("llm_successful_patches_report")
        patch_dir = BASE_DIR / PATHS_CONFIG.get("llm_generated_patches_dir")
        report_output_path = BASE_DIR / PATHS_CONFIG.get("llm_patch_application_report")

    if not os.path.exists(input_json):
        logger.error(f"Input JSON file not found: {input_json}")
        sys.exit(1)

    with open(input_json, "r") as f:
        data = json.load(f)

    # Ensure the output directory for the report exists
    report_output_path.parent.mkdir(exist_ok=True, parents=True)

    strip_level = PATCH_ADOPTER_CONFIG.get("strip_level", 1)
    patch_command = PATCH_ADOPTER_CONFIG.get("patch_tool", "patch")

    patch_adopter = PatchAdopter(
        target_source_path=target_source_path,
        patch_dir=patch_dir,
        report_output_path=str(report_output_path),
        strip_level=strip_level,
        patch_command=patch_command
    )

    patches_to_apply = data if isinstance(data, list) else data.get("patches", [])
    total_patches = len(patches_to_apply)
    yield {"type": "progress", "completed": 0, "total": total_patches}

    if not patches_to_apply:
        logger.warning(f"No patches found in {input_json} to apply.")
        # Create an empty report and exit
        patch_adopter.save_report()
        yield {"type": "summary", "data": patch_adopter.generate_summary()}
        return

    for i, patch_info in enumerate(patches_to_apply):
        patch_file = os.path.basename(patch_info.get("output_path") or patch_info.get("patch_file", ""))
        project_rel_path = patch_info.get("project")

        logger.info(
            f"[{i+1}/{len(patches_to_apply)}] "
            f"Applying '{patch_file}' to project '{project_rel_path}'..."
        )
        result = patch_adopter.apply_patch(patch_info, source=source)
        patch_adopter.patch_results["patches"].append(result)
        yield {"type": "progress", "completed": i + 1, "total": total_patches}

    patch_adopter.save_report()
    summary = patch_adopter.generate_summary()
    end_time = time.time()
    logger.info(f"Adoption for '{source}' finished in {end_time - start_time:.2f}s")
    yield {"type": "summary", "data": summary}


def main():
    """Main function to run the patch adoption process."""
    args = parse_args()
    source = args.source
    
    # These paths are environment-dependent.
    # TODO: These should be moved to a configuration file.
    target_source_path = os.getenv("AOSP_SOURCE_PATH")
    if not target_source_path:
        logger.error("AOSP_SOURCE_PATH environment variable not set.")
        sys.exit(1)

    logger.info("=" * 80)
    logger.info(f"🚀 Starting Patch Adopter for '{source}' patches.")
    logger.info(f"    - AOSP Source: {target_source_path}")
    logger.info(f"    - Strip Level: {strip_level}")
    logger.info(f"    - Patch Tool:  {patch_command}")
    logger.info("=" * 80)

    run_adoption_step(source, target_source_path)


if __name__ == "__main__":
    main()
